# Data Engineering Project Requirements Document

**Project Name:** {{ Project Name }}  
**Business Unit:** {{ Your Team Name }}  
**Company:** {{ Your Company Name }}  
**Document Version:** {{ Document Version }}  
**Date:** {{DATE}}

---

## Revision History

| Version | Author | Date | Description |
|---------|--------|------|-------------|
| 1.0     |        |      | Initial requirements gathering draft |
|         |        |      |             |

---

## 1. Business Understanding

### Background
*Record the current "As-Is" state. Is there a manual process? Is a legacy system failing to scale? Describe why the business is seeking a new solution now.*
___
.
.
.
___

### Business Objectives
*Describe the primary goal. What business questions are we trying to answer? (e.g., "We need to understand customer lifetime value across three different platforms.")*

___
.
.
.
___

### Business Success Criteria
*How will the business stakeholders judge this?*
* **Quantitative:** e.g., "Reduce report generation time from 5 hours to 10 minutes."
* **Qualitative:** e.g., "Enable marketing team to perform self-service analysis without SQL knowledge."

___
.
.
.
___

## 2. Inventory of Resources

### Team

| Name | Organization | Role | Contact Information |
|------|--------------|------|---------------------|
|      |              | Project Sponsor (Owner) |                     |
|      |              | Data Engineer (Lead) |                     |
|      |              | Subject Matter Expert (SME) |                     |
|      |              | Security/Compliance Officer |                     |

### Data Source Deep Dive
*List the technical details of the data we need to ingest.*

| Source Name | Storage Type (API/DB/S3) | Connection Method | Frequency (Batch/Stream) | Est. Volume | Contains PII? |
|-------------|--------------------------|-------------------|--------------------------|-------------|---------------|
| e.g. CRM    | Salesforce API           | OAuth2            | Daily                    | 50k rows/day| Yes           |
| e.g. ERP    | Postgres SQL             | Read Replica      | Hourly                   | 10 GB total | No            |
|             |                          |                   |                          |             |               |

### Software & Infrastructure Stack
* **Orchestration:** (e.g., ADF, Apache Airflow, Dagster)
* **Storage:** (e.g., Snowflake, BigQuery, Databricks)
* **Transformation:** (e.g., dbt, Spark)
* **Visualization:** (e.g., Tableau, Power BI)

---

## 3. Detailed Requirements

### Functional Requirements (The "What")
* **Data Grain:** What does one row represent?
* **Historical Data:** Do we need to get/store historical data? How many years of backfill are required?
* **Deletes:** How should we handle records deleted in the source? (Hard vs. Soft deletes)
* **Transformations:** List specific business logic, aggregations, or currency conversions needed.

### Non-Functional Requirements (The "How")
* **Data Latency:** How "fresh" does the data need to be? (Real-time, 15 min, Daily?)
* **Data Quality Rules:** What defines "bad" data? (e.g., "Emails must contain @", "Price cannot be negative")
* **Retention:** How long must data be stored in the warehouse/lake?
* **Security:** Who is authorized to see this data? Does it need row/column/object-level security?

---

## 4. Stakeholder Discovery Questions
*Use these questions during interviews to uncover hidden complexities:*

1.  **Source Stability:** "How often does the source schema change, and who notifies the data team?"
2.  **Accuracy vs. Latency:** "If we have a choice, is it more important that the data is 100% accurate or available within seconds?"
3.  **Downstream Impact:** "Which specific reports or automated decisions will break if this pipeline fails for 4 hours?"
4.  **Data Lineage:** "Is there a 'golden record' or master list for this data, or are there conflicting sources?"

---

## 5. Constraints, Risks, and Assumptions

### Constraints
* *e.g., "The solution must stay within a $500/month Snowflake budget."*
* *e.g., "No data can leave the EU region due to GDPR."*

### Risks and Contingencies
| Risk Event | Probability | Impact | Mitigation Plan |
|------------|-------------|--------|-----------------|
| API Rate Limiting | High | Medium | Implement exponential backoff in ingestion script. |
| Source data downtime | Low | High | Build alerts and local caching for the last successful state. |

---

## 6. Project Outputs & Success

### Technical Project Goals
*Describe the technical architecture milestones.*



* **Bronze Layer:** Raw ingestion of all 4 source tables.
* **Silver Layer:** Cleaned, deduplicated, and typed data models.
* **Gold Layer:** Business-ready aggregate tables for the "Sales Dashboard."

### Project Success Criteria (Technical)
* **Performance:** Pipeline must finish within 30 minutes of trigger.
* **Reliability:** 99.9% uptime for the production data warehouse.
* **Auditability:** Every row must have an `inserted_at` and `source_system` metadata tag.

---

## 7. Glossary (Terminology)
* **SCD Type 2:** Slowly Changing Dimension used to track historical changes.
* **PII:** Personally Identifiable Information (requires masking).
* **[Term]:** [Definition]